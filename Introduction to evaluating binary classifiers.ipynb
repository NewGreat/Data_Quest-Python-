{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction To The Data\n",
    "Instructions Use the LogisticRegression method predict to return the label for each observation in the dataset, admissions. Assign the returned list to labels.\n",
    "Add a new column to the admissions Dataframe named predicted_label that contains the values from labels.\n",
    "Use the Series method value_counts and the print function to display the distribution of the values in the label column.\n",
    "Use the Dataframe method head and the print function to display the first 5 rows in admissions.\n",
    "Hint\n",
    "Use bracket notation to assign a list of values to a new column in a Dataframe: admissions[\"label\"] = labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.177277</td>\n",
       "      <td>594.102992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.412655</td>\n",
       "      <td>631.528607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.728097</td>\n",
       "      <td>553.714399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.093559</td>\n",
       "      <td>551.089985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141923</td>\n",
       "      <td>537.184894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit       gpa         gre\n",
       "0      0  3.177277  594.102992\n",
       "1      0  3.412655  631.528607\n",
       "2      0  2.728097  553.714399\n",
       "3      0  3.093559  551.089985\n",
       "4      0  3.141923  537.184894"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "labels = model.predict(admissions[[\"gpa\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.177277</td>\n",
       "      <td>594.102992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.412655</td>\n",
       "      <td>631.528607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.728097</td>\n",
       "      <td>553.714399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.093559</td>\n",
       "      <td>551.089985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141923</td>\n",
       "      <td>537.184894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit       gpa         gre  label\n",
       "0      0  3.177277  594.102992      0\n",
       "1      0  3.412655  631.528607      0\n",
       "2      0  2.728097  553.714399      0\n",
       "3      0  3.093559  551.089985      0\n",
       "4      0  3.141923  537.184894      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions[\"label\"] = labels\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions.rename(columns= {\"label\" : \"predicted_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    598\n",
       "1     46\n",
       "Name: predicted_label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions[\"predicted_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     1\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "Name: predicted_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(admissions[\"predicted_label\"][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.177277</td>\n",
       "      <td>594.102992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.412655</td>\n",
       "      <td>631.528607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.728097</td>\n",
       "      <td>553.714399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.093559</td>\n",
       "      <td>551.089985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141923</td>\n",
       "      <td>537.184894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit       gpa         gre  predicted_label\n",
       "0      0  3.177277  594.102992                0\n",
       "1      0  3.412655  631.528607                0\n",
       "2      0  2.728097  553.714399                0\n",
       "3      0  3.093559  551.089985                0\n",
       "4      0  3.141923  537.184894                0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit       gpa         gre  predicted_label\n",
      "0      0  3.177277  594.102992                0\n",
      "1      0  3.412655  631.528607                0\n",
      "2      0  2.728097  553.714399                0\n",
      "3      0  3.093559  551.089985                0\n",
      "4      0  3.141923  537.184894                0\n"
     ]
    }
   ],
   "source": [
    "print(admissions[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Accuracy\n",
    "Instructions Rename the admit column from the admissions Dataframe to actual_label so it's more clear which column contains the predicted labels (predicted_label) and which column contains the actual labels (actual_label).\n",
    "Compare the predicted_label column with the actual_label column.\n",
    "Use a double equals sign (==) to compare the 2 Series objects and assign the resulting Series object to matches.\n",
    "Use conditional filtering to filter admissions to just the rows where matches is True. Assign the resulting Dataframe to correct_predictions.\n",
    "Display the first 5 rows in correct_predictions to make sure the values in the predicted_label and actual_label columns are equal.\n",
    "Calculate the accuracy and assign the resulting float value to accuracy.\n",
    "Display accuracy using the print function.\n",
    "Hint\n",
    "The accuracy is just the number of elements in correct_predictions divided by the total number of observations (or number of elements in the admissions Dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.177277</td>\n",
       "      <td>594.102992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.412655</td>\n",
       "      <td>631.528607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.728097</td>\n",
       "      <td>553.714399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.093559</td>\n",
       "      <td>551.089985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141923</td>\n",
       "      <td>537.184894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual_label       gpa         gre  predicted_label\n",
       "0             0  3.177277  594.102992                0\n",
       "1             0  3.412655  631.528607                0\n",
       "2             0  2.728097  553.714399                0\n",
       "3             0  3.093559  551.089985                0\n",
       "4             0  3.141923  537.184894                0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.rename(columns= {\"admit\" : \"actual_label\"}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "match = admissions[\"actual_label\"] == admissions[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = match[admissions[\"actual_label\"] == admissions[\"predicted_label\"]]\n",
    "correct_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 644 entries, 0 to 643\n",
      "Data columns (total 5 columns):\n",
      "admit              644 non-null int64\n",
      "gpa                644 non-null float64\n",
      "gre                644 non-null float64\n",
      "predicted_label    644 non-null int64\n",
      "actual_label       644 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 30.2 KB\n"
     ]
    }
   ],
   "source": [
    "admissions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit              1.548077\n",
      "gpa                1.548077\n",
      "gre                1.548077\n",
      "predicted_label    1.548077\n",
      "actual_label       1.548077\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "accuracy = admissions.count() / correct_predictions.count()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary Classification Outcomes\n",
    "Instructions Extract all of the rows where predicted_label and actual_label both equal 1. Then, calculate the number of true positives and assign to true_positives.\n",
    "Extract all of the rows where predicted_label and actual_label both equal 0. Then, calculate the number of true negatives and assign to true_negatives.\n",
    "Display both true_positives and true_negatives.\n",
    "Hint\n",
    "Use the & operator to combine filtering criteria in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "6      False\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10     False\n",
       "11     False\n",
       "12     False\n",
       "13     False\n",
       "14     False\n",
       "15     False\n",
       "16     False\n",
       "17     False\n",
       "18     False\n",
       "19     False\n",
       "20     False\n",
       "21     False\n",
       "22     False\n",
       "23     False\n",
       "24     False\n",
       "25     False\n",
       "26     False\n",
       "27     False\n",
       "28     False\n",
       "29     False\n",
       "       ...  \n",
       "614     True\n",
       "615    False\n",
       "616    False\n",
       "617     True\n",
       "618    False\n",
       "619    False\n",
       "620    False\n",
       "621     True\n",
       "622    False\n",
       "623    False\n",
       "624    False\n",
       "625    False\n",
       "626    False\n",
       "627    False\n",
       "628     True\n",
       "629    False\n",
       "630    False\n",
       "631    False\n",
       "632    False\n",
       "633    False\n",
       "634     True\n",
       "635    False\n",
       "636     True\n",
       "637    False\n",
       "638    False\n",
       "639    False\n",
       "640    False\n",
       "641    False\n",
       "642    False\n",
       "643    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_match_positives = (admissions[\"actual_label\"] == 1) & (admissions[\"predicted_label\"] == 1)\n",
    "binary_match_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409    True\n",
      "412    True\n",
      "417    True\n",
      "434    True\n",
      "446    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "true_positives = binary_match_positives[(admissions[\"actual_label\"] == 1) & (admissions[\"predicted_label\"] == 1)]\n",
    "print(true_positives.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "5       True\n",
       "6       True\n",
       "7       True\n",
       "8       True\n",
       "9      False\n",
       "10      True\n",
       "11      True\n",
       "12      True\n",
       "13      True\n",
       "14      True\n",
       "15      True\n",
       "16      True\n",
       "17      True\n",
       "18      True\n",
       "19      True\n",
       "20      True\n",
       "21      True\n",
       "22      True\n",
       "23      True\n",
       "24      True\n",
       "25      True\n",
       "26      True\n",
       "27      True\n",
       "28      True\n",
       "29      True\n",
       "       ...  \n",
       "614    False\n",
       "615    False\n",
       "616    False\n",
       "617    False\n",
       "618    False\n",
       "619    False\n",
       "620    False\n",
       "621    False\n",
       "622    False\n",
       "623    False\n",
       "624    False\n",
       "625    False\n",
       "626    False\n",
       "627    False\n",
       "628    False\n",
       "629    False\n",
       "630    False\n",
       "631    False\n",
       "632    False\n",
       "633    False\n",
       "634    False\n",
       "635    False\n",
       "636    False\n",
       "637    False\n",
       "638    False\n",
       "639    False\n",
       "640    False\n",
       "641    False\n",
       "642    False\n",
       "643    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_match_negatives = (admissions[\"actual_label\"] == 0) & (admissions[\"predicted_label\"] == 0)\n",
    "binary_match_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "true_negatives = binary_match_negatives[(admissions[\"actual_label\"] == 0) & (admissions[\"predicted_label\"] == 0)]\n",
    "print(true_negatives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sensitivity\n",
    "Instructions Calculate the number of false negatives (where the model predicted rejected but the student was actually admitted) and assign to false_negatives.\n",
    "Calculate the sensitivity and assign the computed value to sensitivity.\n",
    "Display sensitivity.\n",
    "Hint\n",
    "Use the formula, Luke!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admissions[binary_match_positives])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_false_negatives = (admissions[\"actual_label\"] == 1) & (admissions[\"predicted_label\"] == 0)\n",
    "binary_false_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives = binary_false_negatives[(admissions[\"actual_label\"] == 1) & (admissions[\"predicted_label\"] == 0)]\n",
    "false_negatives.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12704918032786885\n"
     ]
    }
   ],
   "source": [
    "sensitivity = 31/(31+213)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Specificity\n",
    "Instructions Calculate the number of false positives (where the model predicted admitted but the student was actually rejected) and assign to false_positives.\n",
    "Calculate the specificity and assign the computed value to specificity.\n",
    "Display specificity.\n",
    "Hint\n",
    "Use the formula, Luke!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admissions[binary_match_negatives])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binary_false_negatives = (admissions[\"actual_label\"] == 0) & (admissions[\"predicted_label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives = binary_false_negatives[(admissions[\"actual_label\"] == 0) & (admissions[\"predicted_label\"] == 1)]\n",
    "false_positives.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n"
     ]
    }
   ],
   "source": [
    "specificity = 385/(385 + 15)\n",
    "print(specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
